{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5913a23b-28f8-493e-9cf2-08844c0df8b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ase\n",
    "import networkx as nx\n",
    "import os\n",
    "from monty.serialization import loadfn\n",
    "from glob import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import h5py\n",
    "import itertools\n",
    "\n",
    "\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.analysis.graphs import MoleculeGraph\n",
    "from pymatgen.analysis.local_env import OpenBabelNN, CovalentBondNN\n",
    "from pymatgen.util.graph_hashing import weisfeiler_lehman_graph_hash\n",
    "\n",
    "from radqm9_pipeline.elements import read_elements\n",
    "from radqm9_pipeline.modules import merge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9975dd-a8da-43fb-954d-2063917a59f5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7d445-481c-42f3-9166-8b2b9cf51680",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_dict = read_elements('/pscratch/sd/m/mavaylon/sam_ldrd/radqm9_pipeline/src/radqm9_pipeline/modules/elements.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de53af-55f7-40e8-9d36-6e5473b6308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "\n",
    "from maggma.stores.mongolike import MongoStore\n",
    "\n",
    "\n",
    "# Single-point/force information\n",
    "force_store = MongoStore(database=\"thermo_chem_storage\",\n",
    "                           collection_name=\"radqm9_trajectories\",\n",
    "                           username=\"thermo_chem_storage_ro\",\n",
    "                           password=\"***REMOVED***\",\n",
    "                           host=\"mongodb07.nersc.gov\",\n",
    "                           port=27017,\n",
    "                           key=\"molecule_id\")\n",
    "force_store.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404170d-262f-48ea-ac93-b9d4a16d006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for item in tqdm(force_store.query({})):\n",
    "    raw_data.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba02cd9-2bbb-49c4-9bcf-68f04a997c9c",
   "metadata": {},
   "source": [
    "# Resolve Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f23ed5-bc7d-44d5-b157-973cf461e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features(data: list):\n",
    "    dataset = []\n",
    "    for item in tqdm(data):\n",
    "        formatted_data={}\n",
    "        formatted_data['mol_id'] = item['molecule_id']\n",
    "        formatted_data['species'] = item['species']\n",
    "        formatted_data['charge'] = item['charge'] \n",
    "        formatted_data['spin'] = item['spin_multiplicity']\n",
    "        formatted_data['geometries'] = item['geometries']\n",
    "        formatted_data['energy'] = item['energies']\n",
    "        formatted_data['gradients'] = item['forces']\n",
    "        formatted_data['mulliken_partial_charges'] = item['mulliken_partial_charges']\n",
    "        formatted_data['mulliken_partial_spins'] = item['mulliken_partial_spins']\n",
    "        formatted_data['resp_partial_charges'] = item['resp_partial_charges']\n",
    "        dataset.append(formatted_data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d57dea-220d-4af6-9c53-7e6c96012199",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = filter_features(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c928d-de26-4eef-8a25-0ebc86fa081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resolve_trajectories(data: list):\n",
    "    resolved_data = []\n",
    "    unequal_data = []\n",
    "    bad_data = []\n",
    "    non_spin_broken = []\n",
    "    spin_broken = []\n",
    "    for item in tqdm(data):\n",
    "        try:\n",
    "            feat = [len(item['geometries']), len(item['gradients']), len(item['energy'])]\n",
    "\n",
    "            feat_set = set(feat)\n",
    "            if len(feat_set) !=1 :\n",
    "                unequal_data.append([item, feat])\n",
    "            else:\n",
    "                len_geo = len(item['geometries'])\n",
    "                if len_geo==1:\n",
    "                    resolved_data.append(item)\n",
    "                elif len_geo > 1:\n",
    "                    item['geometries'] = list(itertools.chain.from_iterable(item['geometries']))\n",
    "                    item['gradients'] = list(itertools.chain.from_iterable(item['gradients']))\n",
    "                    item['energy'] = list(itertools.chain.from_iterable(item['energy']))\n",
    "                    item['mulliken_partial_charges'] = list(itertools.chain.from_iterable(item['mulliken_partial_charges']))\n",
    "                    item['resp_partial_charges'] = list(itertools.chain.from_iterable(item['resp_partial_charges']))\n",
    "               \n",
    "                    try:\n",
    "                        item['mulliken_partial_spins'] = list(itertools.chain.from_iterable(item['mulliken_partial_spins']))\n",
    "                    except TypeError:\n",
    "                        # We will resolve weird spin data later in the pipeline\n",
    "                        pass\n",
    "                    resolved_data.append(item)   \n",
    "                else:\n",
    "                    bad_data.append(item)\n",
    "        except TypeError:\n",
    "            non_spin_broken.append(item)\n",
    "        \n",
    "    return resolved_data, unequal_data, bad_data, non_spin_broken, spin_broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1518800-c387-4938-8da3-de777f2b5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_data, u_data, b_data, non_spin_data, spin_data = resolve_trajectories(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ed0f6-6688-4060-8628-2fe8c5d2eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unique_id(data: list):\n",
    "    for item in tqdm(data):\n",
    "        item['charge_spin'] = str(item['charge']) + str(item['spin'])\n",
    "        item['mol_cs'] = str(item['mol_id']) + str(item['charge_spin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a405bc-25bf-40ac-a664-25d39e249409",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_unique_id(r_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52972a7-974e-4f17-a3ca-d3128068a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension(data: list):\n",
    "    fields = []\n",
    "    for item in tqdm(data): \n",
    "        if len(item['geometries']) == 1:\n",
    "            item['geometries'] = item['geometries'][0]\n",
    "        if len(item['gradients']) == 1:\n",
    "            item['gradients'] = item['gradients'][0]\n",
    "        if len(item['energy']) == 1:\n",
    "            item['energy'] = item['energy'][0]\n",
    "        if len(item['mulliken_partial_charges']) == 1:\n",
    "            item['mulliken_partial_charges'] = item['mulliken_partial_charges'][0]\n",
    "        if len(item['mulliken_partial_spins']) == 1:\n",
    "            item['mulliken_partial_spins'] = item['mulliken_partial_spins'][0]\n",
    "        if len(item['resp_partial_charges']) == 1:\n",
    "            item['resp_partial_charges'] = item['resp_partial_charges'][0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38234f4-5ef8-43c3-9b2c-2431233234f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension(r_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6d10e-8633-4f1a-9afc-3c0c0a4e945f",
   "metadata": {},
   "source": [
    "# Check for Invalid Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181c60b-43d9-49f7-8cfd-dbb226dcdd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(input_list):\n",
    "    flattened_list = []\n",
    "    for item in input_list:\n",
    "        if isinstance(item, list):\n",
    "            flattened_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flattened_list.append(item)\n",
    "    return flattened_list\n",
    "\n",
    "def filter_field(data, field):\n",
    "    shit={}\n",
    "    for item in tqdm(data):\n",
    "        if item[field] is None:\n",
    "            try:\n",
    "                shit[item['charge_spin']].append(item)\n",
    "            except KeyError:\n",
    "                shit[item['charge_spin']] = [item]\n",
    "        elif None in flatten_list(item[field]):\n",
    "            try:\n",
    "                shit[item['charge_spin']].append(item)\n",
    "            except KeyError:\n",
    "                shit[item['charge_spin']] = [item]\n",
    "    return shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981c903-4d86-4b9e-8685-d51f89a6074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc= filter_field(r_data, 'mulliken_partial_charges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac53589-fdb0-4647-a7e2-1071b884948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[x,len(pc[x])] for x in pc.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc8cb3-a952-4924-9d0c-30e399cb9bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps= filter_field(r_data, 'mulliken_partial_spins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0335029-df1c-4f18-9e80-154cc160aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[x,len(ps[x])] for x in ps.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d3b90-1519-46f4-92ec-99af12ee0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpc= filter_field(r_data, 'resp_partial_charges')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f4b1a-3009-4fac-81ce-1d1225d842d7",
   "metadata": {},
   "source": [
    "# Calculate Resp Dipoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc83789-e6ac-4912-b796-f45458894dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_resp_dipole(data: list): #THIS IS GOOD\n",
    "    for item in tqdm(data):\n",
    "        resp_dipole = []\n",
    "        resp_dipole_conv = []\n",
    "        for i in range(len(item['resp_partial_charges'])):\n",
    "            resp_partial_charges = np.array(item['resp_partial_charges'][i])\n",
    "            geometries = np.array(item['geometries'][i])\n",
    "            \n",
    "            # Calculate dipole moment components\n",
    "            dipole_components = resp_partial_charges[:, np.newaxis] * geometries\n",
    "            \n",
    "            # Sum the dipole moment components along axis 0 to get the total dipole moment vector\n",
    "            dipole_moment = np.sum(dipole_components, axis=0)\n",
    "            dipole_moment_conv = np.sum(dipole_components, axis=0)*(1/0.2081943)\n",
    "            \n",
    "            # Append dipole moment to resp_dipole list\n",
    "            resp_dipole.append(dipole_moment.tolist())  # Convert numpy array to list\n",
    "            # Append dipole moment to resp_dipole list\n",
    "            resp_dipole_conv.append(dipole_moment_conv.tolist())  # Convert numpy array to list\n",
    "        \n",
    "        item['calc_resp_dipole_moments'] = resp_dipole_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030ba21-a8fa-44ac-abf0-da0388b24c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_resp_dipole(r_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f22cef-79c4-496c-9187-9be4068389d5",
   "metadata": {},
   "source": [
    "# Fix mulliken ps for 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed55136-bb35-4468-97d2-78a53b0b92bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resolve_mulliken_partial_spins(data: list):\n",
    "    for item in tqdm(data):\n",
    "        if item['charge_spin']=='01':\n",
    "            if item['mulliken_partial_spins'] is None or None in item['mulliken_partial_spins']:\n",
    "                item['mulliken_partial_spins']=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad92063-f851-4085-bb25-5ad80d8a34c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m resolve_mulliken_partial_spins(\u001b[43mr_data\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r_data' is not defined"
     ]
    }
   ],
   "source": [
    "resolve_mulliken_partial_spins(r_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef41c1c-1da1-4c31-b459-2b12e87a4a0c",
   "metadata": {},
   "source": [
    "# Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ef407-b4e4-4129-905d-723359b5afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data: list):\n",
    "    good = []\n",
    "    filtered = []\n",
    "    for item in data:\n",
    "        if item['charge_spin'] != '01':\n",
    "            if len(item['gradients']) < 2:\n",
    "                filtered.append(item)\n",
    "            else:\n",
    "                good.append(item)\n",
    "        else:\n",
    "            good.append(item)\n",
    "    \n",
    "    return good, filtered\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12352fa7-9820-4458-ac13-c8a4b2297e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_data, f_data = filter_data(r_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292b757-d90e-41d0-977f-d6b54a368f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_magnitude_filter(cutoff: float,\n",
    "                           data: list):\n",
    "    \"\"\"\n",
    "    This method returns both data that meets the cuttoff value and data that is equal to or above the cuttoff value.\n",
    "    If this is run before downsampling, it removes the entire data point trajectory.\n",
    "    \n",
    "    Returns: lists\n",
    "    \"\"\"\n",
    "    good = []\n",
    "    bad = []\n",
    "    weird = []\n",
    "    for item in tqdm(data):\n",
    "        forces = item['gradients']\n",
    "        for path_point in forces:\n",
    "            next_item = False\n",
    "            for atom in path_point:\n",
    "                try:\n",
    "                    res = np.sqrt(sum([i**2 for i in atom]))\n",
    "                    if res >= cutoff:\n",
    "                        bad.append(item)\n",
    "                        next_item = True\n",
    "                        break\n",
    "                except TypeError:\n",
    "                    res = np.sqrt(sum([i**2 for i in atom[0]]))\n",
    "                    if res >= cutoff:\n",
    "                        bad.append(item)\n",
    "                        next_item = True\n",
    "                        break\n",
    "            if next_item:\n",
    "                break\n",
    "        if not next_item:\n",
    "            good.append(item)\n",
    "                            \n",
    "    return good, bad, weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ddb51b-22d4-4cf7-a316-cd2b10403484",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data, b_data, w_data = force_magnitude_filter(cutoff=10.0, data=g_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06248700-497f-4bd9-a0c7-450aaf0f36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_charges(data: list, charge: list):\n",
    "    clean = []\n",
    "    bad = []\n",
    "    for item in data:\n",
    "        if item['charge'] not in charge:\n",
    "            clean.append(item)\n",
    "        else:\n",
    "            bad.append(item)\n",
    "    return clean, bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21570c7e-7dd8-48e2-89bb-1f990e3aab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data, b_data = filter_charges(clean_data, [-2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64964f5c-964c-4266-80af-5e15aa338353",
   "metadata": {},
   "source": [
    "# Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277fd69b-ebdc-470d-b70a-e0f4ae479e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_energy(data: list):\n",
    "    for item in tqdm(data):\n",
    "        energy = item['energy']\n",
    "        item['energy'] = [x*27.2114 for x in energy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b3061e-74e5-42a4-8118-1e0e64b2375d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_forces(data: list):\n",
    "    for item in tqdm(data):\n",
    "        forces = item['gradients']\n",
    "        traj_arr = []\n",
    "        for traj_point in forces:\n",
    "            atom_arr = []\n",
    "            for atom in traj_point:\n",
    "                comp_arr = []\n",
    "                for component in atom:\n",
    "                    new_component = component * 51.42208619083232\n",
    "                    comp_arr.append(new_component)\n",
    "                atom_arr.append(comp_arr)\n",
    "            traj_arr.append(atom_arr)\n",
    "        item['gradients'] = traj_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af264dc-6c13-4926-82e1-8c77339e2c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_energy(c_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c54fa9-4cb6-4112-b4da-251f9f3aaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_forces(c_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d8906-0e3e-45b2-a936-cab124053578",
   "metadata": {},
   "source": [
    "# Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ebe8d7-c914-4997-a325-308874a434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_force_trajectory(pair):\n",
    "    \"\"\"\n",
    "    This method will take a specfic spin charge pair. At each point in the optimization trajectory, the \n",
    "    \"\"\"\n",
    "    forces = {}\n",
    "    for i in range(len(pair['gradients'])):\n",
    "        temp = []\n",
    "        for atom in pair['gradients'][i]:\n",
    "            res = np.sqrt(sum([j**2 for j in atom]))\n",
    "            temp.append(res)\n",
    "        forces[i] = np.mean(temp)\n",
    "    del forces[0]\n",
    "    return forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97269a0a-f5b2-4e0e-845b-588e7365a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_trajectory(data: list):\n",
    "    \"\"\"\n",
    "    This takes the cleaned data and will sparsifiy the optimization trajectories. How this is done will depend on the\n",
    "    charge_spin pair:\n",
    "    - Neutral Singlet (0,1): First and Last\n",
    "    - Other: First, Last, and structure with the highest molecular force other than the First.\n",
    "    \n",
    "    Note: Molecular Force is just the average of the force magnitudes of each atom in the molecule:\n",
    "    \"\"\"\n",
    "    bad=[]\n",
    "\n",
    "    for pair in tqdm(data):\n",
    "        try:\n",
    "            if pair['charge_spin'] == '01':\n",
    "                geometries = [pair['geometries'][0], pair['geometries'][-1]]\n",
    "                energies = [pair['energy'][0], pair['energy'][-1]]\n",
    "                grads = [pair['gradients'][0], pair['gradients'][-1]]\n",
    "                mulliken_partial_charges = [pair['mulliken_partial_charges'][0], pair['mulliken_partial_charges'][-1]]\n",
    "                mulliken_partial_spins = [pair['mulliken_partial_spins'][0], pair['mulliken_partial_spins'][-1]]\n",
    "                resp_partial_charges = [pair['resp_partial_charges'][0], pair['resp_partial_charges'][-1]]\n",
    "                dipole_moments_resp = [pair['calc_resp_dipole_moments'][0], pair['calc_resp_dipole_moments'][-1]]\n",
    "\n",
    "                pair['geometries'] = geometries\n",
    "                pair['energies'] = energies\n",
    "                pair['gradients'] = grads\n",
    "                pair['mulliken_partial_charges'] = mulliken_partial_charges\n",
    "                pair['mulliken_partial_spins'] = mulliken_partial_spins\n",
    "                pair['resp_partial_charges'] = resp_partial_charges\n",
    "                pair['calc_resp_dipole_moments'] = dipole_moments_resp\n",
    "            else:\n",
    "                force_dict = average_force_trajectory(pair)\n",
    "                max_index = max(force_dict, key=force_dict.get)\n",
    "\n",
    "                geometries = [pair['geometries'][0], pair['geometries'][max_index], pair['geometries'][-1]]\n",
    "                energies = [pair['energy'][0], pair['energy'][max_index], pair['energy'][-1]]\n",
    "                grads = [pair['gradients'][0], pair['gradients'][max_index], pair['gradients'][-1]]\n",
    "                mulliken_partial_charges = [pair['mulliken_partial_charges'][0], pair['mulliken_partial_charges'][max_index], pair['mulliken_partial_charges'][-1]]\n",
    "                mulliken_partial_spins = [pair['mulliken_partial_spins'][0], pair['mulliken_partial_spins'][max_index], pair['mulliken_partial_spins'][-1]]\n",
    "                resp_partial_charges = [pair['resp_partial_charges'][0], pair['resp_partial_charges'][max_index], pair['resp_partial_charges'][-1]]\n",
    "                dipole_moments_resp = [pair['calc_resp_dipole_moments'][0], pair['calc_resp_dipole_moments'][max_index], pair['calc_resp_dipole_moments'][-1]]\n",
    "\n",
    "\n",
    "                pair['geometries'] = geometries\n",
    "                pair['energies'] = energies\n",
    "                pair['gradients'] = grads\n",
    "                pair['mulliken_partial_charges'] = mulliken_partial_charges\n",
    "                pair['mulliken_partial_spins'] = mulliken_partial_spins\n",
    "                pair['resp_partial_charges'] = resp_partial_charges\n",
    "                pair['calc_resp_dipole_moments'] = dipole_moments_resp\n",
    "        except ValueError:\n",
    "            bad.append(pair)\n",
    "    return bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef587e54-3bba-4787-82ed-d5fa3db1a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_trajectory(g_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b0046-d548-40e2-a49f-f8f59a3394dc",
   "metadata": {},
   "source": [
    "# Read the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff90a5-84e0-4699-8dc0-ce7084761562",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aba2e7-c9ac-4a2b-b846-04b47918ee8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9034b1-72c6-4f1b-960d-606196c83d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_molecule_weight(data: list):\n",
    "    \"\"\"\n",
    "    The method takes in a list of data (either trajectories or single points) and sorts into a distribution\n",
    "    dictionary. The keys are the species/formula and the value of each key is the weight. appearing number of times the species\n",
    "    appears in the dataset.\n",
    "    \"\"\"\n",
    "    dict_dist = {}\n",
    "    for item in tqdm(data):\n",
    "        species_num = []\n",
    "        species=''.join((sorted(item['species'])))\n",
    "        \n",
    "        for element in item['species']:\n",
    "            species_num.append(elements_dict[element])\n",
    "\n",
    "        species_sum = sum(species_num)\n",
    "        try:\n",
    "            dict_dist[species].append(species_sum)\n",
    "            dict_dist[species] = [dict_dist[species][0]]*len(dict_dist[species])\n",
    "        except KeyError:\n",
    "            dict_dist[species] = [species_sum]\n",
    "        \n",
    "    return dict_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db7558b5-008e-499e-93bd-b4f665956384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def molecule_weight(data: list, weight_dict):\n",
    "    \"\"\"\n",
    "    This method takes in data and assigns the mass.\n",
    "    Python does a weird thing floats e.g., {126.15499999999993, 126.15499999999994}, having this and\n",
    "    get_molecule_weight gurantees that species that are the same are not being assigned different weights.\n",
    "    \"\"\"\n",
    "    for item in tqdm(data):\n",
    "        weight = weight_dict[''.join((sorted(item['species'])))][0]\n",
    "        item['molecule_mass'] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5af508-21ca-48d5-bd3e-7c3d974d4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dist = get_molecule_weight(c_data)\n",
    "molecule_weight(c_data, merged_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7b9b0-8e18-4dca-80cd-163209e5fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_to_data(data: list):\n",
    "    \"\"\"\n",
    "    This method buckets the data by the mass such that the dict key is the mass and the values are the data\n",
    "    points.\n",
    "    \"\"\"\n",
    "    dict_data = {}\n",
    "    for item in tqdm(data):\n",
    "        try:\n",
    "            dict_data[item['molecule_mass']].append(item)\n",
    "        except KeyError:\n",
    "            dict_data[item['molecule_mass']] = [item]\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7335fda0-2952-4c14-9972-98050b743aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def length_dict(data: dict):\n",
    "    \"\"\"\n",
    "    This method takes in the output of weight_to_data and returns a dictionary that is sorted from largest\n",
    "    to smallest mass. The keys are the mass and the values are the number of appearances.\n",
    "    \"\"\"\n",
    "    length_dict = {key: len(value) for key, value in data.items()}\n",
    "    sorted_length_dict = {k: length_dict[k] for k in sorted(length_dict, reverse=True)}\n",
    "    \n",
    "    return sorted_length_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d79e99-e3af-4a02-adf7-5eb749b5a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtd = weight_to_data(c_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274dfc67-b652-4cf0-9d88-770d130d98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sld = length_dict(wtd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee15df-b92f-4295-806a-67134cfa5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: make into a function\n",
    "\n",
    "The split method is as follows:\n",
    "I have a dictionary that is sorted from highest mass to lowest mass. The value of each key is the number of times\n",
    "that mass is in the data. Another way to think of this, is the number of trajectories or SPs that have that\n",
    "mass. \n",
    "\n",
    "We have a list for each split that stores the the masses.\n",
    "We have three variables that store the size of the splits. \n",
    "\n",
    "Each iteration will add a mass to a split. This ensures that the mass is in one split. This means that that species\n",
    "is only in that split. \n",
    "\n",
    "It will continue to add until all the masses have been added. \n",
    "\"\"\"\n",
    "\n",
    "# Take initial points (the highest masses) and have them in the data\n",
    "train_mass = [152.037] # EVAN WILL NEED TO ADJUST THE MASSES OF INITIAL POINTS FOR NEW DATA\n",
    "test_mass = [144.09200000000007]\n",
    "val_mass = [143.10800000000006]\n",
    "\n",
    "train = sld[152.037] # trackers for dataset sizes\n",
    "test = sld[144.09200000000007]\n",
    "val = sld[143.10800000000006]\n",
    "\n",
    "sld.pop(152.037)\n",
    "sld.pop(144.09200000000007)\n",
    "sld.pop(143.10800000000006)\n",
    "\n",
    "# Sort the data \n",
    "# data is a dict: mass-># of trajs\n",
    "for mass in sld:\n",
    "    temp_total = train+val+test\n",
    "    train_ratio = .65-(train/temp_total)\n",
    "    test_ratio = .25-(test/temp_total)\n",
    "    val_ratio = .1-(val/temp_total)\n",
    "    \n",
    "    if train_ratio > val_ratio and train_ratio>test_ratio:\n",
    "        train_mass.append(mass)\n",
    "        train += sld[mass]\n",
    "    elif val_ratio > train_ratio and val_ratio>test_ratio:\n",
    "        val_mass.append(mass)\n",
    "        val += sld[mass]\n",
    "    elif test_ratio > val_ratio and test_ratio>train_ratio:\n",
    "        test_mass.append(mass)\n",
    "        test += sld[mass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a3c3e-13fb-4454-a28e-5ad853a2c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "train/(train+val+test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f119cd-a533-4ceb-a86e-ec908f3900de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sld = length_dict(wtd) # you need to call this again yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442ae58-010c-4463-9fed-ad4ba6470263",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset={key: sld[key] for key in train_mass if key in sld}\n",
    "test_subset={key: sld[key] for key in test_mass if key in sld}\n",
    "val_subset={key: sld[key] for key in val_mass if key in sld}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703fcead-586e-459f-8790-a5ef591e6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp=[[x]*train_subset[x] for x in train_subset]\n",
    "test_temp=[[x]*test_subset[x] for x in test_subset]\n",
    "val_temp=[[x]*val_subset[x] for x in val_subset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f1d49-eeac-47fa-b66e-ab7a3f086e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "train_subset_merged = list(chain.from_iterable(train_temp))\n",
    "test_subset_merged = list(chain.from_iterable(test_temp))\n",
    "val_subset_merged = list(chain.from_iterable(val_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512c0de-4b0e-4b03-85b8-494be769fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_merged = list(chain.from_iterable(train_temp))\n",
    "\n",
    "plt.hist(train_subset_merged, bins=50)\n",
    "plt.ylabel('Frequency (log)')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Molecule Mass')\n",
    "plt.title('Train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2184fcd-2fbb-454d-a4c7-3ff8c90d2dc5",
   "metadata": {},
   "source": [
    "# Make Manual switches if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b8576-b7e6-4e1f-940d-2d37b3074ce5",
   "metadata": {},
   "source": [
    "# Build ASE atoms and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d80437-ed75-4536-8243-b8c329628e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_atoms(data: dict,\n",
    "                energy: str = None,\n",
    "                forces: str = None,\n",
    "                charge:str = None,\n",
    "                spin:str = None,\n",
    "                train = False) -> ase.Atoms:\n",
    "    \"\"\" \n",
    "    Populate Atoms class with atoms in molecule.\n",
    "        atoms.info : global variables\n",
    "        atoms.array : variables for individual atoms\n",
    "        \n",
    "    Both \"energy\" and \"forces\" are the dict strings in data.\n",
    "    \"\"\"\n",
    "    atom_list = []\n",
    "    for i in range(len(data['geometries'])):\n",
    "        atoms = ase.atoms.Atoms(\n",
    "            symbols=data['species'],\n",
    "            positions=data['geometries'][i]\n",
    "        )\n",
    "        atoms.arrays['mulliken_partial_charges']=np.array(data['mulliken_partial_charges'][i])\n",
    "        atoms.arrays['mulliken_partial_spins']=np.array(data['mulliken_partial_spins'][i])\n",
    "        atoms.arrays['resp_partial_charges']=np.array(data['resp_partial_charges'][i])\n",
    "        atoms.info['calc_resp_dipole_moments']=np.array(data['calc_resp_dipole_moments'][i])\n",
    "        \n",
    "        if energy is not None:\n",
    "            atoms.info['energy'] = data[energy][i]\n",
    "        if forces is not None:\n",
    "            atoms.arrays['forces'] = np.array(data[forces][i])\n",
    "        if charge is not None:\n",
    "             atoms.info['charge'] = data[charge]\n",
    "        if spin is not None:\n",
    "            atoms.info['spin'] = data[spin]\n",
    "        atoms.info['mol_id'] = data['mol_id']\n",
    "        if i == 0:\n",
    "            atoms.info['position_type'] = 'start'\n",
    "        if i == 1:\n",
    "            if data['charge_spin'] == '0,1':\n",
    "                atoms.info['position_type'] = 'end'\n",
    "            else:\n",
    "                atoms.info['position_type'] = 'middle'\n",
    "        if i == 2:\n",
    "            atoms.info['position_type'] = 'end'\n",
    "        atom_list.append(atoms)\n",
    "    return atom_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ac2359-a2dc-4e31-8efd-8249b4d1d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_minimal_atoms_iterator(data: list,\n",
    "                         train=False):\n",
    "    \"\"\"\n",
    "    This method assumes the data has been validated. This will create ASE atoms to be written.\n",
    "    \n",
    "    The input needs to be a list of lists that contain the event dictionaries. Each inner list needs to represent all the events for a single\n",
    "    mol_id.\n",
    "    \"\"\"\n",
    "    data_set=[]\n",
    "    for point in tqdm(data):\n",
    "        atoms=build_minimal_atoms(point, energy='energies', forces='gradients', charge='charge', spin='spin', train=train)\n",
    "        data_set+=atoms\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609bfeb4-eb58-4661-ba9b-1e2bbdb14c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "build = {}\n",
    "for split in data:\n",
    "    if split == 'train':\n",
    "        build[split] = build_minimal_atoms_iterator(data[split], train=True)\n",
    "    else:\n",
    "        build[split] = build_minimal_atoms_iterator(data[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01de502-e117-4dd7-9d2a-ab4eef92beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data: dict,\n",
    "                   file_name:str,\n",
    "                   path:str):\n",
    "    \"\"\"\n",
    "    This method will handle the I/O for writing the data to xyz files to the path provided.\n",
    "    \"\"\"\n",
    "    train_data = data['train']\n",
    "    val_data = data['val']\n",
    "    test_data = data['test']\n",
    "    \n",
    "    train_file = os.path.join(path,file_name+'_train.xyz')\n",
    "    ase.io.write(train_file, train_data,format=\"extxyz\")\n",
    "     \n",
    "    val_file = os.path.join(path,file_name+'_val.xyz')\n",
    "    ase.io.write(val_file, val_data,format=\"extxyz\")\n",
    "    \n",
    "    test_file = os.path.join(path,file_name+'_test.xyz')\n",
    "    ase.io.write(test_file, test_data,format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3c291-4091-41de-bf9e-978c14a0ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to xyz\n",
    "create_dataset(build, 'rad_qm9_65_10_25_full_data_new_52024', full_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d1682-befd-4499-8441-3787082439d4",
   "metadata": {},
   "source": [
    "# Chunk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e26d6c-2308-4763-b736-135821d2796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the xyz train \n",
    "path='...'\n",
    "atoms_list = ase.io.read(path, index=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa51ff-6ea8-4d21-8556-169653148227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_molecule_weight_ase(data: list):\n",
    "    dict_dist = {}\n",
    "    data_dict = {}\n",
    "    for item in tqdm(data):\n",
    "        species_num = []\n",
    "        species=''.join((sorted(item.get_chemical_symbols())))\n",
    "        \n",
    "        for element in item.get_chemical_symbols():\n",
    "            species_num.append(elements_dict[element])\n",
    "\n",
    "        species_sum = sum(species_num)\n",
    "        try:\n",
    "            dict_dist[species].append(species_sum)\n",
    "            # python does a weird thing floats e.g., {126.15499999999993, 126.15499999999994}\n",
    "            dict_dist[species] = [dict_dist[species][0]]*len(dict_dist[species])\n",
    "        except KeyError:\n",
    "            dict_dist[species] = [species_sum]\n",
    "        \n",
    "    return dict_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff3b1f-9806-4d1a-b09a-f8d1e7223dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecule_weight_ase(data: list, weight_dict):\n",
    "    for item in tqdm(data):\n",
    "        species=''.join((sorted(item.get_chemical_symbols())))\n",
    "        weight = weight_dict[species][0]\n",
    "        item.info['weight'] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcccf27-af28-42d5-b00e-d82ca0b7119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=get_molecule_weight_ase(atoms_list)\n",
    "molecule_weight_ase(atoms_list, mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29df1d47-2dca-4f4d-a8c9-ced4f3f5db6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weight_to_data_ase(data: list):\n",
    "    dict_data = {}\n",
    "    for item in tqdm(data):\n",
    "        try:\n",
    "            dict_data[item.info['weight']].append(item)\n",
    "        except KeyError:\n",
    "            dict_data[item.info['weight']] = [item]\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42728eea-6211-45f4-b7e5-aba09c3d0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "ase_data = weight_to_data_ase(atoms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c775d-8738-4cbd-bed3-43c0dfe5c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data: dict, chunks: list):\n",
    "    return_data = {}\n",
    "    foo_data = data\n",
    "    total=0\n",
    "    for pair in tqdm(data):\n",
    "        total+=len(data[pair])\n",
    "    \n",
    "    sizes = []\n",
    "    for item in chunks:\n",
    "        temp_size = round(total*item)\n",
    "        sizes.append(temp_size)\n",
    "    \n",
    "    for i in range(len(chunks)):\n",
    "        chunk_data = []\n",
    "        if i==0:\n",
    "            for key in tqdm(data):\n",
    "                if len(foo_data[key]) != 0:\n",
    "                    # print(len(foo_data[key]))\n",
    "                    sample_size = math.floor(chunks[i] * len(foo_data[key]))\n",
    "                    chunk_data += foo_data[key][:sample_size]\n",
    "                    foo_data[key] = foo_data[key][sample_size:]\n",
    "            return_data[i] = chunk_data\n",
    "        else:\n",
    "            counter = 0\n",
    "            for j in range(50):\n",
    "                if counter < sizes[i]-sizes[i-1]:\n",
    "                    for key in data:\n",
    "                        if len(foo_data[key]) != 0:\n",
    "                            sample_size = math.floor((chunks[i]-chunks[i-1]) * len(foo_data[key]))\n",
    "                            # print(sample_size)\n",
    "                            # print(len(foo_data[key]))\n",
    "                            add_on = foo_data[key][:sample_size]\n",
    "                            chunk_data += add_on\n",
    "                            # print(len(foo_data[key][:sample_size])/len(foo_data[key]))\n",
    "                            foo_data[key] = foo_data[key][sample_size:]\n",
    "                            counter += len(add_on)\n",
    "                            if counter >= sizes[i]-sizes[i-1]:\n",
    "                                break\n",
    "                else:\n",
    "                    # print(counter)\n",
    "                    # print(sizes[i])\n",
    "                    # print(sizes[i]/total)\n",
    "                    # print(len(chunk_data)/total)\n",
    "                    break\n",
    "                # if counter > total:\n",
    "                #     print('bad')\n",
    "                #     break\n",
    "\n",
    "            return_data[i] = chunk_data + return_data[i-1]\n",
    "    return return_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efbb64-b4e5-4476-afa7-9eb9a98fd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = chunk_data(ase_data, [.05, .1, .25, .5, .75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3d68b-d7ad-460d-bedc-109d47f644a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in cd:\n",
    "    print(len(cd[key])/len(atoms_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b836d-9f64-40ca-8a51-b01934cbe135",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/Traj_Zip_Final/Final_Chunked_Singlet_Doublet/singlet','rad_qm9_traj_subset'+'_train05.xyz')\n",
    "ase.io.write(chunk_file, cd[0],format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e809cfd-e5ea-4d91-a924-aa317422719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/Traj_Zip_Final/Final_Chunked_Singlet_Doublet/singlet','rad_qm9_traj_subset'+'_train10.xyz')\n",
    "ase.io.write(chunk_file, cd[1],format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff04a1e-05df-46ff-b456-ebae5a194fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/Traj_Zip_Final/Final_Chunked_Singlet_Doublet/singlet','rad_qm9_traj_subset'+'_train25.xyz')\n",
    "ase.io.write(chunk_file, cd[2],format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13964bd2-826d-4c34-95bc-54bdc45ccb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/Traj_Zip_Final/Final_Chunked_Singlet_Doublet/singlet','rad_qm9_traj_subset'+'_train50.xyz')\n",
    "ase.io.write(chunk_file, cd[3],format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e743b-1b6b-4aa1-af58-764e72309198",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/Traj_Zip_Final/Final_Chunked_Singlet_Doublet/singlet','rad_qm9_traj_subset'+'_train75.xyz')\n",
    "ase.io.write(chunk_file, cd[4],format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f17370-6d80-4fa3-9f6e-29b8f598d0aa",
   "metadata": {},
   "source": [
    "# Test Charge Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633ca1d-71e9-4935-b52a-9eabb7096955",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_read = '...' # xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c7cc4-1397-4683-b473-6b6a1dc90ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms_list = ase.io.read(test_read, index=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f8205f-0d21-4022-939f-015abe2fa66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_dict = {}\n",
    "for item in atoms_list:\n",
    "    charge_spin = str(item.info['charge']) + str(item.info['spin'])\n",
    "    try:\n",
    "        charge_dict[charge_spin].append(item)\n",
    "    except KeyError:\n",
    "        charge_dict[charge_spin] = [item]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0608b1-5072-48e3-95f0-e1b42b43fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/TestSets','rad_qm9_traj'+'_test01.xyz')\n",
    "ase.io.write(charge_file, charge_dict['01'],format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eba081-0ca9-4c7e-95f5-f8b9a6a52777",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/TestSets','rad_qm9_traj'+'_test12.xyz')\n",
    "ase.io.write(charge_file, charge_dict['12'],format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b342fda3-5da0-4557-99fb-03558e282e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/TestSets','rad_qm9_traj'+'_test_neg12.xyz')\n",
    "ase.io.write(charge_file, charge_dict['-12'],format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836fbefd-f838-46ec-adef-e680711c7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/TestSets','rad_qm9_traj'+'_test_neg12.xyz')\n",
    "ase.io.write(charge_file, charge_dict['-12'],format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683f719-424d-4100-a0a2-cfeeaf7721b3",
   "metadata": {},
   "source": [
    "# Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f2e2a-6d58-4a9b-83bb-0e2d0d81cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='...'\n",
    "train = ase.io.read(path, index=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9f3e8-a611-4c15-ab8d-79b7f35f6a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='...'\n",
    "val = ase.io.read(path, index=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61524a17-491e-49d7-888a-ca1cb653f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='...'\n",
    "test = ase.io.read(path, index=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ae194-d7b6-43a0-8fb3-2ca512052a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cs_dict = {}\n",
    "for item in tqdm(train):\n",
    "    key = str(item.info['charge'])+str(item.info['spin'])\n",
    "    try:\n",
    "        train_cs_dict[key].append(item)\n",
    "    except KeyError:\n",
    "        train_cs_dict[key] = [item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ab46c-338f-49b2-b4f0-e373a189a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cs_dict = {}\n",
    "for item in tqdm(val):\n",
    "    key = str(item.info['charge'])+str(item.info['spin'])\n",
    "    try:\n",
    "        val_cs_dict[key].append(item)\n",
    "    except KeyError:\n",
    "        val_cs_dict[key] = [item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5ccd1-33fe-4033-a6e0-a72ad971ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cs_dict = {}\n",
    "for item in tqdm(test):\n",
    "    key = str(item.info['charge'])+str(item.info['spin'])\n",
    "    try:\n",
    "        test_cs_dict[key].append(item)\n",
    "    except KeyError:\n",
    "        test_cs_dict[key] = [item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f7286-84ff-4081-89d1-9b18f41ef228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this for relative energies\n",
    "for key in test_cs_dict:\n",
    "    file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/DaFinal/subsets','rad_qm9_7_1_24_converted_E_F_convrespdm_train_'+key+'.xyz')\n",
    "    ase.io.write(file, train_cs_dict[key], format=\"extxyz\")\n",
    "    \n",
    "    file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/DaFinal/subsets','rad_qm9_7_1_24_converted_E_F_convrespdm_val_'+key+'.xyz')\n",
    "    ase.io.write(file, val_cs_dict[key],format=\"extxyz\")\n",
    "    \n",
    "    file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/DaFinal/subsets','rad_qm9_7_1_24_converted_E_F_convrespdm_test_'+key+'.xyz')\n",
    "    ase.io.write(file, test_cs_dict[key],format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21effbd4-37a2-4333-afe6-e606bd5ebb7a",
   "metadata": {},
   "source": [
    "### Doublet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11dcf86-146f-4b20-b339-f425d91ff495",
   "metadata": {},
   "outputs": [],
   "source": [
    "doublet_train = []\n",
    "doublet_val = []\n",
    "doublet_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a524d1eb-5b2f-46d6-9f1d-dbef61518c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(train):\n",
    "    if item.info['spin'] ==2:\n",
    "        doublet_train.append(item)\n",
    "\n",
    "for item in tqdm(val2):\n",
    "    if item.info['spin'] ==2:\n",
    "        doublet_val.append(item)\n",
    "\n",
    "for item in tqdm(test):\n",
    "    if item.info['spin'] ==2:\n",
    "        doublet_test.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71156d50-ef3e-4754-a59b-7e62bc7d63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/Traj_Zip_Final/FINAL_SUBSETS/subsets/doublet','rad_qm9_7_25_24_converted_E_F_convrespdm_train.xyz')\n",
    "ase.io.write(file, doublet_train, format=\"extxyz\")\n",
    "\n",
    "file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/Traj_Zip_Final/FINAL_SUBSETS/subsets/doublet','rad_qm9_7_25_24_converted_E_F_convrespdm_val.xyz')\n",
    "ase.io.write(file, doublet_val,format=\"extxyz\")\n",
    "\n",
    "file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/Traj_Zip_Final/FINAL_SUBSETS/subsets/doublet','rad_qm9_7_25_24_converted_E_F_convrespdm_test.xyz')\n",
    "ase.io.write(file, doublet_test,format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63daac-df2b-4642-810b-3353c5e44037",
   "metadata": {},
   "source": [
    "### Singlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb57504-526b-4c6d-a12a-52a95ef46b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sing_train = []\n",
    "sing_val = []\n",
    "sing_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c46e5a-7869-48bc-8108-f5ce9011c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(train):\n",
    "    if item.info['spin'] ==1:\n",
    "        doublet_train.append(item)\n",
    "\n",
    "for item in tqdm(val2):\n",
    "    if item.info['spin'] ==1:\n",
    "        doublet_val.append(item)\n",
    "\n",
    "for item in tqdm(test):\n",
    "    if item.info['spin'] ==1:\n",
    "        doublet_test.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e701ed2a-b422-4702-a36c-c1dcc38420bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write similar to doublet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df103cb9-0032-4184-9465-a20408eeee7c",
   "metadata": {},
   "source": [
    "# Relative Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb02b3e-755b-40d9-83d3-70d84eb1894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_energies(data: list, stats: dict):\n",
    "    for item in tqdm(data):\n",
    "        key = str(item.info['charge'])+str(item.info['spin'])\n",
    "        lookup_sum = 0\n",
    "        for num in item.arrays['numbers']:\n",
    "            lookup_sum += eval(stats[key]['atomic_energies'])[num]\n",
    "        \n",
    "        rel = item.info['energy'] - lookup_sum\n",
    "        item.info['relative_energy'] = rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b25ba5-6d3f-402b-8707-0f5b5f63ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_single_json_energies(data: list, stats: dict):\n",
    "    for item in tqdm(data):\n",
    "        lookup_sum = 0\n",
    "        for num in item.arrays['numbers']:\n",
    "            lookup_sum += eval(stats['atomic_energies'])[num]\n",
    "        \n",
    "        rel = item.info['total_energy'] - lookup_sum\n",
    "        item.info['relative_energy'] = rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f1f72-6ddb-469a-bcb5-a4f1de86263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/pscratch/sd/m/mavaylon/chem_final_data/Traj/DaFinal/subsets/sub_-12/h5/statistics.json', 'r') as f:\n",
    "    data_n12 = json.load(f)\n",
    "    \n",
    "with open('/pscratch/sd/m/mavaylon/chem_final_data/Traj/DaFinal/subsets/sub_01/h5/statistics.json', 'r') as f:\n",
    "    data_01 = json.load(f)\n",
    "    \n",
    "with open('/pscratch/sd/m/mavaylon/chem_final_data/Traj/DaFinal/subsets/sub_03/h5/statistics.json', 'r') as f:\n",
    "    data_03 = json.load(f)\n",
    "    \n",
    "with open('/pscratch/sd/m/mavaylon/chem_final_data/Traj/DaFinal/subsets/sub_12/h5/statistics.json', 'r') as f:\n",
    "    data_12 = json.load(f)\n",
    "\n",
    "stats_dict= {'-12': data_n12,\n",
    "             '01': data_01,\n",
    "             '03': data_03,\n",
    "             '12': data_12}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b45926-6567-455e-acc1-a1e461aca6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_energies(train, stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cec4be-e254-4f42-880e-98ac61394ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_energies(val, stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690e3a7-f34f-4c11-988b-786bc1fbd54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_energies(test, stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2089f4-90c6-43df-8ff9-b94d0e0db767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184679d-3e25-4f0e-9f10-7a24f944319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_build_atoms_rel(data: dict,\n",
    "                energy: str = None,\n",
    "                forces: str = None,\n",
    "                charge:str = None,\n",
    "                spin:str = None,\n",
    "                train = False) -> ase.Atoms:\n",
    "    \"\"\" \n",
    "    Populate Atoms class with atoms in molecule.\n",
    "        atoms.info : global variables\n",
    "        atoms.array : variables for individual atoms\n",
    "        \n",
    "    Both \"energy\" and \"forces\" are the dict strings in data.\n",
    "    \"\"\"\n",
    "    atom_list = []\n",
    "    for item in tqdm(data):\n",
    "        atoms = ase.atoms.Atoms(\n",
    "            numbers=item.arrays['numbers'],\n",
    "            positions=item.arrays['positions']\n",
    "        )\n",
    "        atoms.info['total_energy'] = item.info['total_energy']\n",
    "        atoms.info['relative_energy'] = item.info['relative_energy']\n",
    "        atoms.info['mol_id'] = item.info['mol_id']\n",
    "        atoms.arrays['forces'] = np.array(item.arrays['forces'])\n",
    "        atoms.info['charge'] =  item.info['charge']\n",
    "        atoms.info['spin'] =  item.info['spin'] \n",
    "        atoms.info['position_type'] = item.info['position_type']\n",
    "        atoms.arrays['mulliken_partial_charges']=np.array(item.arrays['mulliken_partial_charges'])\n",
    "        atoms.arrays['mulliken_partial_spins']=np.array(item.arrays['mulliken_partial_spins'])\n",
    "        atoms.arrays['resp_partial_charges']=np.array(item.arrays['resp_partial_charges'])\n",
    "        atoms.info['calc_resp_dipole_moments']=np.array(item.info['calc_resp_dipole_moments'])\n",
    "        \n",
    "        atom_list.append(atoms)\n",
    "    return atom_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a711645-7653-4133-ab34-61e32e4291ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = re_build_minimal_atoms_rel(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8bbe61-06e9-44f9-ba4b-e6ddf3dc8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "reval = re_build_minimal_atoms_rel(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef11fd-2822-4c2e-9804-2e0f38057a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "retest = re_build_minimal_atoms_rel(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89edb32f-2943-40ba-8d38-b63bc6d66bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b018add-a192-472e-a30f-d46e73dbc907",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/DaFinal/Full','rad_qm9_7_10_24_converted_E_F_convrespdm_relenergy_train.xyz')\n",
    "ase.io.write(file, retrain, format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3647b9b-4b36-4c3a-8df4-e8a646aec4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/DaFinal/Full','rad_qm9_7_10_24_converted_E_F_convrespdm_relenergy_val.xyz')\n",
    "ase.io.write(file, reval,format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab346f43-b491-4cc1-9325-6eaffdaa9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join('/pscratch/sd/m/mavaylon/chem_final_data/Traj/DaFinal/Full','rad_qm9_7_10_24_converted_E_F_convrespdm_relenergy_test.xyz')\n",
    "ase.io.write(file, retest,format=\"extxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702dfcd-a96b-44e9-a655-ef5988618045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
